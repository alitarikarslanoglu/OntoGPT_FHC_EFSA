{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alitarikarslanoglu/OntoGPT_FHC_EFSA/blob/faq/claim_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwQOD-er8dOY"
      },
      "source": [
        "#Claim Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gDA7Ef_8XXl"
      },
      "source": [
        "## System Check and Instalation of Reqirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn5NCVxx4hd8",
        "outputId": "4dc650cf-7c78-4af6-c51e-751d671b9441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Apr  2 21:52:36 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "  !nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXGb5oMP8iz7"
      },
      "source": [
        "### System Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l5acTUe7kcH",
        "outputId": "ac89408b-b288-46ef-b061-36a17568e67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.20 requires torch==2.0.1, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m--2024-04-02 22:00:25--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 108.177.119.190, 108.177.119.93, 108.177.119.91, ...\n",
            "Connecting to dl.google.com (dl.google.com)|108.177.119.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 107229972 (102M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 102.26M   185MB/s    in 0.6s    \n",
            "\n",
            "2024-04-02 22:00:26 (185 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [107229972/107229972]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libu2f-udev libudev1 libvulkan1 mesa-vulkan-drivers systemd-hwe-hwdb udev\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libu2f-udev libvulkan1 mesa-vulkan-drivers systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 6 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 12.5 MB/120 MB of archives.\n",
            "After this operation, 405 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libu2f-udev all 1.1.10-3build2 [4,190 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.2 [10.7 MB]\n",
            "Get:6 /content/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 123.0.6312.105-1 [107 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 12.5 MB in 1s (10.8 MB/s)\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../0-udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libu2f-udev.\n",
            "Preparing to unpack .../1-libu2f-udev_1.1.10-3build2_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.10-3build2) ...\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "Preparing to unpack .../2-libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../3-google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (123.0.6312.105-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../4-mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../5-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libu2f-udev (1.1.10-3build2) ...\n",
            "Setting up google-chrome-stable (123.0.6312.105-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 liblzo2-2 snapd squashfs-tools\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 liblzo2-2 snapd squashfs-tools\n",
            "0 upgraded, 7 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 25.7 MB of archives.\n",
            "After this operation, 105 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.3 [595 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.61.3+22.04 [24.7 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Fetched 25.7 MB in 0s (61.1 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 122031 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.3_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.3) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.61.3+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.61.3+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.3) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.61.3+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 122353 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.3 [186 kB]\n",
            "Fetched 186 kB in 0s (2,504 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 122374 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq torch==2.1.0 --progress-bar off\n",
        "!pip install -qqq transformers==4.31.0 --progress-bar off\n",
        "!pip install -qqq langchain==0.0.266 --progress-bar off\n",
        "!pip install -qqq chromadb==0.4.5 --progress-bar off\n",
        "!pip install -qqq pypdf==3.15.0 --progress-bar off\n",
        "!pip install -qqq xformers==0.0.20 --progress-bar off\n",
        "!pip install -qqq sentence_transformers==2.2.2 --progress-bar off\n",
        "!pip install -qqq InstructorEmbedding==1.0.1 --progress-bar off\n",
        "!pip install -qqq pdf2image==1.16.3 --progress-bar off\n",
        "!pip install -qqq selenium==4.14.0 --progress-bar off\n",
        "!pip install -qqq bs4 --progress-bar off\n",
        "!pip install -qqq tqdm --progress-bar off\n",
        "!pip install -qqq PyPDF2 --progress-bar off\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb && apt install ./google-chrome-stable_current_amd64.deb\n",
        "!pip install -qqq  auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/ --progress-bar off\n",
        "!apt install chromium-chromedriver\n",
        "!sudo apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_myN0hFC9i-"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuMbQHQ-8tT0"
      },
      "outputs": [],
      "source": [
        "#import\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from langchain import HuggingFacePipeline, PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from pdf2image import convert_from_path\n",
        "from transformers import AutoTokenizer, TextStreamer, pipeline\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import datetime\n",
        "import shutil\n",
        "import glob\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "from PyPDF2 import PdfReader\n",
        "import random\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeGALbMxCYTY"
      },
      "source": [
        "## Retrival"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO8Hv_2MC0LJ"
      },
      "source": [
        "### Selenium WebDriver for Chrome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBKbHYS4Cyqd"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "def driversetup():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    #run Selenium in headless mode\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\")\n",
        "    #overcome limited resource problems\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "    options.add_argument(\"lang=en\")\n",
        "    #open Browser in maximized mode\n",
        "    options.add_argument(\"start-maximized\")\n",
        "    #disable infobars\n",
        "    options.add_argument(\"disable-infobars\")\n",
        "    #disable extension\n",
        "    options.add_argument('ignore-certificate-errors')\n",
        "    options.add_argument('--ignore-ssl-errors=yes')\n",
        "    options.add_argument(\"--disable-extensions\")\n",
        "    options.add_argument(\"--incognito\")\n",
        "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    return driver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQrZQAQdDIH1"
      },
      "source": [
        "###Expert Report/CSV Retrival"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhMihj7NC47p",
        "outputId": "ce4f7956-5c0a-491d-99fb-b9a9ab0480c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Xgb7GwakWa_wEiOAeiFz-sUg8Uo0NO3F\n",
            "To: /content/data/tree.xlsx\n",
            "\r  0% 0.00/541k [00:00<?, ?B/s]\r100% 541k/541k [00:00<00:00, 84.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!mkdir pdfs\n",
        "!gdown 1Xgb7GwakWa_wEiOAeiFz-sUg8Uo0NO3F -O data/tree.xlsx\n",
        "!rm -r pdfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFRrY8zSDRgq"
      },
      "outputs": [],
      "source": [
        "claims = pd.read_excel('data/tree.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WvUTyEcFhAA"
      },
      "source": [
        "### List of EFSA Opinion References Links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_I8RLzAFud9"
      },
      "source": [
        "In the google sheet created by experts, \"EFSA Opinion Reference\" feature contains the codes of the documents. Following code creates the usable links to those Scientific opinions\n",
        "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2009.1226"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikb2JH-vDk0s",
        "outputId": "a7cf5326-b310-4db6-a756-9181980ea2a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 237/237 [00:00<00:00, 33455.05it/s]\n"
          ]
        }
      ],
      "source": [
        "res = []\n",
        "for k in tqdm(range(len(claims['EFSA Opinion Reference'])), position=0, leave=True):\n",
        "  i = claims['EFSA Opinion Reference'][k]\n",
        "  claim = claims['Claim'][k]\n",
        "  if str(i) == 'nan':\n",
        "    continue\n",
        "  row = re.split(',',str(i))\n",
        "  for j in row:\n",
        "    args = re.split(';|:',j)\n",
        "    if len(args)!=3:\n",
        "      continue\n",
        "    res.append('https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.' + args[0].replace(\" \",\"\") + '.' + args[2].replace(\" \",\"\") + '#'+ claim + '#' + str(k))\n",
        "\n",
        "  row = re.split('-',str(i))\n",
        "  args = re.split('-',j)\n",
        "  if len(args)!=3:\n",
        "    continue\n",
        "  res.append('https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.' + args[1].replace(\" \",\"\") + '.' + args[2].replace(\" \",\"\") + '#'+ claim + '#' + str(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t7jHAIAYSgX9",
        "outputId": "156b74f3-2c9e-4dcf-f5a6-1bdf8d61d1bc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2009.1252#ALA contributes to the maintenance of normal blood cholesterol levels#1'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OI77wgcGdrN"
      },
      "outputs": [],
      "source": [
        "def getpage(url, c, out_subdir):\n",
        "  log = ''\n",
        "  try:\n",
        "    for k in os.listdir('pdfs/'+out_subdir+'/'):\n",
        "      n = re.split('-',k)\n",
        "      if len(n)!=8:\n",
        "        continue\n",
        "      if (str(c) + '.pdf') == n[7]:\n",
        "        log += f'\\tFile n {c} skipped already present\\tfilename:{k}\\n'\n",
        "        return log\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  driver = driversetup()\n",
        "  driver.get(url)\n",
        "  driver.close()\n",
        "\n",
        "  name = 'pdfs/'+ out_subdir + '/efsa-' + str(datetime.datetime.now().strftime(\"%Y-%m-%d-at-%H-%M-\")) + str(c) + '.pdf'\n",
        "\n",
        "  try:\n",
        "    filename = max([f for f in os.listdir('.')],key=os.path.getctime)\n",
        "    try:\n",
        "      os.mkdir('pdfs/'+ out_subdir)\n",
        "    except:\n",
        "      pass\n",
        "    shutil.move(filename,os.path.join('.',name))\n",
        "  except:\n",
        "    log += f'File n {c} failed reffer to the followring url.\\n{url}\\n'\n",
        "  return log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa3tG2svTmrV"
      },
      "source": [
        "For each folders containing pdfs for claims, a text file created giving the overview of the claims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4I4y77nm2Gp"
      },
      "outputs": [],
      "source": [
        "!rm -r pdfs\n",
        "!mkdir pdfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv08NCZ3TI5h",
        "outputId": "a8c1cd3f-7395-4527-d51f-b5330c6d20a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 297/297 [18:53<00:00,  3.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File n 217 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2010.4114\n",
            "File n 218 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2010.4114\n",
            "File n 219 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2010.4114\n",
            "File n 222 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2010.4114\n",
            "File n 291 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2013.00234\n",
            "File n 292 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2014.00073\n",
            "File n 293 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2013.00040\n",
            "File n 294 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2015.00437\n",
            "File n 295 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2015.00375\n",
            "File n 296 failed reffer to the followring url.\n",
            "https://efsa.onlinelibrary.wiley.com/doi/pdf/10.2903/j.efsa.2011.00972\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "counter = 0\n",
        "\n",
        "log = ''\n",
        "for i in tqdm(res, position=0, leave=True):\n",
        "  sep = i.split('#')\n",
        "  log+=getpage(sep[0],counter, sep[2])\n",
        "  with open('./pdfs/' + sep[2] + '/claim.txt', 'w') as f:\n",
        "    f.write(sep[1])\n",
        "  counter += 1\n",
        "\n",
        "print(log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1ejlv3NXVwb"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd82W5i9XzuP"
      },
      "source": [
        "### Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lv4OVUQwTPC6"
      },
      "outputs": [],
      "source": [
        "model_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "model_basename = \"model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr46o-HfXeEN",
        "outputId": "4014b6f2-0bc6-42ae-897a-61a50be82fd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO - The layer lm_head is not quantized.\n",
            "INFO:auto_gptq.modeling._base:The layer lm_head is not quantized.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
        "model = AutoGPTQForCausalLM.from_quantized(\n",
        "    model_path,\n",
        "    revision=\"gptq-4bit-128g-actorder_True\",\n",
        "    model_basename=model_basename,\n",
        "    use_safetensors=True,\n",
        "    trust_remote_code=True,\n",
        "    inject_fused_attention=False,\n",
        "    device=DEVICE,\n",
        "    quantize_config=None,\n",
        ")\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0kfRa2oY9If"
      },
      "source": [
        "### Prompt Settings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aVl4J7dZFPa"
      },
      "source": [
        "Any given prompt will be connected with the default system promt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Vfv0sZYXyCt"
      },
      "outputs": [],
      "source": [
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def generate_prompt(prompt: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
        "    return f\"\"\"\n",
        "[INST] <>\n",
        "{system_prompt}\n",
        "<>\n",
        "\n",
        "{prompt} [/INST]\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tn_pMXtlcrGI"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
        "\n",
        "template = generate_prompt(\n",
        "    \"\"\"\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\",\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        ")\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-KcVBiCcQaQ"
      },
      "source": [
        "### Text Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeQp8ircZOz9",
        "outputId": "d90d30d1-676c-438c-b699-ce4185594469"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.0.1+cu118 with CUDA 1108 (you have 2.2.1+cu121)\n",
            "    Python  3.10.11 (you have 3.10.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=1024,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.15,\n",
        "    streamer=streamer, # Ask this\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zq609_5ZX3U"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq09i0jnczdi"
      },
      "outputs": [],
      "source": [
        "def isClaimInDir(claimN, dir) -> bool:\n",
        "  if os.path.isdir(dir + '/' + str(claimN)):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def retrieveFood(claimN) -> str:\n",
        "  if not isClaimInDir(str(claimN), 'pdfs'):\n",
        "    return '~'\n",
        "  docs = []\n",
        "  for k in os.listdir('pdfs/'+str(claimN)):\n",
        "    if k.split('.')[1] == 'pdf':\n",
        "      docs.append(k)\n",
        "  for k in docs:\n",
        "    reader = PdfReader('pdfs/'+str(claimN)+'/'+k)\n",
        "    text = reader.pages[0].extract_text().replace('\\n','')\n",
        "    claim_match = re.search(r'the substantiation of health claims related to (.*?) and', text)\n",
        "    if claim_match:\n",
        "      claim_text = claim_match.group(1)\n",
        "      print(f'Constituent Found: {claim_text}')\n",
        "      return claim_text\n",
        "\n",
        "def claimReport(claimN):\n",
        "  claimN = str(claimN)\n",
        "\n",
        "  #Preconditions\n",
        "  if not isClaimInDir(claimN, 'pdfs'):\n",
        "    return 'Claim Not Found in PDFS'\n",
        "  if isClaimInDir(claimN, 'db'):\n",
        "    shutil.rmtree(f'db/{claimN}')\n",
        "\n",
        "  #Find Food\n",
        "  constituent = retrieveFood(claimN)\n",
        "  if constituent == '~':\n",
        "    return 'Could not identify constituent'\n",
        "\n",
        "  #Load QA retrieval and embedding model\n",
        "  loader = PyPDFDirectoryLoader(\"pdfs/\" + claimN)\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "  texts = text_splitter.split_documents(loader.load())\n",
        "  db = Chroma.from_documents(texts, HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": DEVICE}), persist_directory=\"db/\"+claimN)\n",
        "  qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        "  )\n",
        "  print('---------------------------------------------------------')\n",
        "  result = qa_chain('Prompt: Considering the text, what are all the claimed effects proposed by the panel? Please answer specifically following the structure: {Constituent} contributes to {Action} of subject assuming the target population is {Target} based on the paragraph {Paragraph}. Repeat for all claimed effects assumed by the panel, knowing that the constituent is ' + constituent + ' and that {Action} is a verb. Hint: All the claimed effects are listed in the index as subparagraph 2.x under the second paragraph titled \"Relevance of the claimed effect to human health.\" Be sure to check the index for a comprehensive list of claimed effects. Additional Instructions: Keep in mind that each claimed effect has its own subparagraph under the second paragraph titled \"Relevance of the claimed effect to human health,\" which spans over multiple pages and ends with the scientific substantiation of the claimed effect. At the end, please copy all the previously mentioned paragraphs from the provided source document in full.')\n",
        "  print('---------------------------------------------------------')\n",
        "  # result_B = qa_chain('Considering the text,what are the other academic papers cited? They are mostly containing citations as \"(author et al., publish year)\". Give the exact paragraph provides the supporting evidences with citations. At the end, please copy all the previously mentioned paragraphs from the provided source document in full.')\n",
        "  # result_B = qa_chain('Generate detailed responses for each claimed effect proposed by the panel regarding the constituent ' + constituent +'. Include the complete text from the document for each claimed effect.')\n",
        "  print('---------------------------------------------------------')\n",
        "\n",
        "  #print(docs)\n",
        "  return [result,result_B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QBZcF69dO5O",
        "outputId": "763fcacc-ca26-4783-95a1-bbc58135c6d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Constituent Found: alpha-linolenic acid\n",
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n",
            "---------------------------------------------------------\n",
            " Based on the provided text, the claimed effects proposed by the panel are:\n",
            "\n",
            "{Constituent} contributes to {Action} of subject assuming the target population is {Target} based on the paragraph {Paragraph}.\n",
            "\n",
            "1. Alpha-linolenic acid contributes to the maintenance of normal blood cholesterol concentrations assuming the target population is the general population based on paragraph 2.1.\n",
            "2. Alpha-linolenic acid helps maintain a healthy blood pressure assuming the target population is the general population based on paragraph 2.2.\n",
            "\n",
            "Please note that these claimed effects are listed in the index as subparagraphs 2.1 and 2.2 under the second paragraph titled \"Relevance of the claimed effect to human health.\"\n",
            "\n",
            "Here are the full paragraphs from the provided source document:\n",
            "\n",
            "\"2. Relevance of the claimed effect to human health\n",
            "\n",
            "2.1. Maintenance of normal blood cholesterol concentrations (ID 493)\n",
            "\n",
            "The claimed effect is “blood cholesterol”. The Panel assumes that the target population is the general population. In the context of the proposed wordings, the Panel notes that the claimed effect relates to the maintenance of normal blood cholesterol concentrations.\n",
            "\n",
            "A cause and effect relationship has been established between the dietary intake of alpha-linolenic acid and the reduction of LDL-cholesterol concentrations.\n",
            "\n",
            "2.2. Maintenance of healthy blood pressure (ID 625)\n",
            "\n",
            "The claimed effect is “helps maintain a healthy blood pressure”. The Panel assumes the target population is the general population. Maintenance of normal blood pressure is beneficial to human health.\n",
            "\n",
            "The evidence provided is insufficient to establish a cause and effect relationship between the dietary intake of ALA and the maintenance of normal blood pressure.\"\n",
            "---------------------------------------------------------\n",
            " Based on the given text, there are two academic papers cited:\n",
            "\n",
            "1. \"18314732, 2009, 10, Downloaded from <https://efsa.onlinelibrary.wiley.com/doi/10.2903/j.efsa.2009.1252>, Wiley Online Library on [20/03/2024]\"\n",
            "2. \"18314732, 2011, 6, Downloaded from <https://efsa.onlinelibrary.wiley.com/doi/10.2903/j.efsa.2011.2203>, Wiley Online Library on [20/03/2024]\"\n",
            "\n",
            "The supporting evidence with citations is provided in the following paragraphs:\n",
            "\n",
            "\"Documentation provided to EFSA ........................................................................................................... 9\n",
            "References .............................................................................................................................................. 10\n",
            "Appendices ............................................................................................................................................. 12\"\n",
            "\n",
            "Therefore, the exact paragraphs from the provided source document that provide supporting evidences with citations are:\n",
            "\n",
            "\"Documentation provided to EFSA ........................................................................................................... 9\n",
            "References .............................................................................................................................................. 10\n",
            "Appendices ............................................................................................................................................. 12\"\n",
            "\n",
            "Please note that these paragraphs do not contain any explicit citations or references, but they are considered as supporting evidence for the paper's claims.\n",
            "---------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "t = claimReport(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-WoDuq3dO2r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI9fCrwHdOwd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjUQ7Q0IdOmc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNUb/WKeHwaKtbCGia4O7dn",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
